{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750c9213-321d-4bfc-a304-1bb2adf6b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "class Neo4jExporter:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "    \n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "    \n",
    "    def export_nodes(self):\n",
    "        query = \"\"\"\n",
    "        WITH ['EFO', 'GO', 'LINCS', 'NCBI', 'SNOMEDCT_US', 'PUBCHEM', 'GTEXEXP', 'EXPBINS', 'IDGD', 'UBERON', 'IDGP', 'UNIPROTKB', 'HGNC'] as SAB_LIST, \n",
    "        \"MATCH (t:Term)-[r1]-(cde:Code)-[r2]-(con:Concept) \n",
    "            WHERE cde.SAB in $sabList\n",
    "            RETURN con.CUI as CUI, \n",
    "            CASE cde.SAB\n",
    "                WHEN 'EFO' THEN 'EFO'\n",
    "                when 'NCBI' then 'NCBI'\n",
    "                when 'UNIPROTKB' then 'Protein'\n",
    "                when 'HGNC' then 'Gene'\n",
    "                when 'GO' then 'GO'\n",
    "                when 'EFO' then 'EFO'\n",
    "                when 'SNOMEDCT_US' then 'Disease'\n",
    "                when 'PUBCHEM' then 'Compound'\n",
    "                when 'EXPBINS' then 'Tissue'\n",
    "                when 'UBERON' then 'Tissue'\n",
    "                when 'GTEXEXP' then 'Tissue'\n",
    "            end as Node_label,\n",
    "            cde.SAB as SAB, cde.CODE as Code, t.name as Label, t.name as Synonyms\" AS query\n",
    "        CALL apoc.export.csv.query(query,\"nodes.tsv\", {params: {sabList: SAB_LIST}, separator: '\\t'}) \n",
    "        YIELD file, nodes, relationships, properties, time\n",
    "        RETURN file, nodes, relationships, properties, time\n",
    "        \"\"\"\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(query)\n",
    "            for record in result:\n",
    "                print(f\"Exported to {record['file']} with {record['nodes']} nodes and {record['relationships']} relationships in {record['time']} ms\")\n",
    "\n",
    "    def export_relationships(self):\n",
    "        # query = \"\"\"\n",
    "        # WITH ['EFO', 'GO', 'LINCS', 'NCBI', 'SNOMEDCT_US', 'PUBCHEM', 'GTEXEXP', 'EXPBINS', 'IDGD', 'UBERON', 'IDGP', 'UNIPROTKB', 'HGNC'] as SAB_LIST, \n",
    "        # \"MATCH (source_code:Code)-[r1]-(source_concept:Concept)-[relationOfInterest]-(target_concept:Concept)-[r2]-(target_code:Code)\n",
    "        # WHERE source_code.SAB IN $sabList AND target_code.SAB IN $sabList\n",
    "        # RETURN source_concept.CUI as source, type(relationOfInterest) as relation, target_concept.CUI as target, source_code.CodeID as source_label, target_code.CodeID as target_label, relationOfInterest.SAB as SAB\" as query\n",
    "        # CALL apoc.export.csv.query(query, \"relationships.tsv\", {params: {sabList: SAB_LIST, batchSize: 100000, separator: '\\t'}})\n",
    "        # YIELD file, nodes, relationships, properties, time\n",
    "        # RETURN file, nodes, relationships, properties, time\n",
    "        # \"\"\"\n",
    "\n",
    "        query = \"\"\"\n",
    "        WITH ['EFO', 'GO', 'LINCS', 'NCBI', 'SNOMEDCT_US', 'PUBCHEM', 'GTEXEXP', 'EXPBINS', 'IDGD', 'UBERON', 'IDGP', 'UNIPROTKB', 'HGNC'] as SAB_LIST\n",
    "        CALL apoc.export.csv.query(\n",
    "        \"MATCH (source_code:Code)-[r1]-(source_concept:Concept)-[relationOfInterest]-(target_concept:Concept)-[r2]-(target_code:Code)\n",
    "        WHERE source_code.SAB IN $SAB_LIST AND target_code.SAB IN $SAB_LIST\n",
    "        WITH source_code, target_code, source_concept, target_concept, relationOfInterest,\n",
    "        CASE WHEN source_code.SAB IN ['NCBI'] THEN 'NCBI'\n",
    "        WHEN source_code.SAB IN ['UNIPROTKB'] THEN 'Protein'\n",
    "        WHEN source_code.SAB IN ['HGNC'] THEN 'Gene'\n",
    "        WHEN source_code.SAB IN ['GO'] THEN 'GO'\n",
    "        WHEN source_code.SAB IN ['EFO', 'SNOMEDCT_US'] THEN 'Disease'\n",
    "        WHEN source_code.SAB IN ['PUBCHEM'] THEN 'Compound'\n",
    "        WHEN source_code.SAB IN ['EXPBINS', 'UBERON', 'GTEXEXP'] THEN 'Tissue'\n",
    "        ELSE 'Unknown' END as sourceLabel,\n",
    "        CASE WHEN target_code.SAB IN ['NCBI'] THEN 'NCBI'\n",
    "        WHEN target_code.SAB IN ['UNIPROTKB'] THEN 'Protein'\n",
    "        WHEN target_code.SAB IN ['HGNC'] THEN 'Gene'\n",
    "        WHEN target_code.SAB IN ['GO'] THEN 'GO'\n",
    "        WHEN target_code.SAB IN ['EFO', 'SNOMEDCT_US'] THEN 'Disease'\n",
    "        WHEN target_code.SAB IN ['PUBCHEM'] THEN 'Compound'\n",
    "        WHEN target_code.SAB IN ['EXPBINS', 'UBERON', 'GTEXEXP'] THEN 'Tissue'\n",
    "        ELSE 'Unknown' END as targetLabel\n",
    "        RETURN source_concept.CUI as source, type(relationOfInterest) as relation, target_concept.CUI as target,\n",
    "        sourceLabel, targetLabel, relationOfInterest.SAB as SAB\",\n",
    "        \"relationships.tsv\",\n",
    "        {params: {SAB_LIST: SAB_LIST}, batchSize: 100000, separator: ','}\n",
    "        ) YIELD file, nodes, relationships, properties, time\n",
    "        RETURN file, nodes, relationships, properties, time;\n",
    "        \"\"\"\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(query)\n",
    "            for record in result:\n",
    "                print(f\"Exported to {record['file']} with {record['nodes']} nodes and {record['relationships']} relationships in {record['time']} ms\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace these values with your Neo4j connection details\n",
    "    uri = \"bolt://chiltepin.health.unm.edu:4500\"\n",
    "    user = \"neo4j\"\n",
    "    password = \"Hello@001\"\n",
    "\n",
    "    exporter = Neo4jExporter(uri, user, password)\n",
    "    exporter.export_nodes()\n",
    "    exporter.export_relationships()\n",
    "    exporter.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4675021d-3145-4603-ba9a-ca4e6af776f6",
   "metadata": {},
   "source": [
    "Before running import code, copy (or move) the export nodes.tsv and relationships.tsv to the import directory of new container \n",
    "(Currently /home/www/htdocs/x/cfde/distillery/data/CKG/import)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2ddb899-81ef-4688-a363-f3d406fbc48e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import csv\n",
    "\n",
    "class Neo4jImporter:\n",
    "    def __init__(self, uri, user, password, batch_size=1000):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "    \n",
    "    def import_nodes(self):\n",
    "        query = \"\"\"\n",
    "        CALL apoc.periodic.iterate(\n",
    "            \"LOAD CSV WITH HEADERS FROM 'file:///nodes.tsv' AS row FIELDTERMINATOR ',' RETURN row\", \n",
    "            \"WITH row, trim(row.Node_label) AS label\n",
    "            CALL apoc.create.node([label], {\n",
    "                CUI: trim(row.CUI),\n",
    "                SAB: trim(row.SAB),\n",
    "                node_code: trim(row.Code),\n",
    "                node_label: trim(row.node_label),\n",
    "                node_synonyms: trim(row.Synonyms)\n",
    "            }) YIELD node\n",
    "            RETURN node;\",\n",
    "            {batchSize:500000, parallel:true}\n",
    "        )\n",
    "        YIELD batches, total\n",
    "        RETURN batches, total\n",
    "        \"\"\"\n",
    "\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(query)\n",
    "            for record in result:\n",
    "                print(f\"Imported {record['total']} nodes in {record['batches']} batches.\")\n",
    "\n",
    "    def delete_duplicate_nodes(self):\n",
    "        query = \"\"\"\n",
    "        MATCH (c)\n",
    "        WHERE c.CUI IS NOT NULL\n",
    "        WITH c.CUI AS cui, COLLECT(c) AS cnodes\n",
    "        WHERE SIZE(cnodes) > 1\n",
    "        FOREACH (n IN TAIL(cnodes) | DETACH DELETE n);\n",
    "        \"\"\"\n",
    "\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(query)\n",
    "            for record in result:\n",
    "                print(\"result: \", record)\n",
    "        \n",
    "        print(\"Duplicate Nodes deleted\")\n",
    "\n",
    "    def create_node_index(self):\n",
    "        queries = [\n",
    "        \"CREATE INDEX IF NOT EXISTS FOR (n:EFO) ON (n.CUI);\",\n",
    "        \"CREATE INDEX IF NOT EXISTS FOR (n:NCBI) ON (n.CUI);\",\n",
    "        \"CREATE INDEX IF NOT EXISTS FOR (n:Protein) ON (n.CUI);\",\n",
    "        \"CREATE INDEX IF NOT EXISTS FOR (n:Gene) ON (n.CUI);\",\n",
    "        \"CREATE INDEX IF NOT EXISTS FOR (n:GO) ON (n.CUI);\",\n",
    "        \"CREATE INDEX IF NOT EXISTS FOR (n:Disease) ON (n.CUI);\",\n",
    "        \"CREATE INDEX IF NOT EXISTS FOR (n:Compound) ON (n.CUI);\",\n",
    "        \"CREATE INDEX IF NOT EXISTS FOR (n:Tissue) ON (n.CUI);\",\n",
    "        ]\n",
    "\n",
    "        with self.driver.session() as session:\n",
    "            for query in queries:\n",
    "                result = session.run(query)\n",
    "                for record in result:\n",
    "                    print(\"result: \", record)\n",
    "        \n",
    "        print(\"created indexes\")\n",
    "        \n",
    "    def fetch_and_process_relationships(self, output_file='relationships_processed.csv'):\n",
    "        query = \"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM 'file:///relationships.tsv' AS row FIELDTERMINATOR ','\n",
    "        RETURN DISTINCT trim(row.sourceLabel) AS source_label, trim(row.targetLabel) AS target_label, trim(row.relation) AS relation, trim(row.source) AS source, trim(row.target) AS target\n",
    "        \"\"\"\n",
    "        \n",
    "        relationships = []\n",
    "        batch_count = 0\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(query)\n",
    "            for record in result:\n",
    "                relationships.append({\n",
    "                    'source_label': record['source_label'],\n",
    "                    'target_label': record['target_label'],\n",
    "                    'relation': record['relation'],\n",
    "                    'source': record['source'],\n",
    "                    'target': record['target']\n",
    "                })\n",
    "                if len(relationships) >= self.batch_size:\n",
    "                        self.save_to_file(relationships, output_file, batch_count)\n",
    "                        batch_count += 1\n",
    "                        relationships.clear()\n",
    "\n",
    "            if relationships:\n",
    "                self.save_to_file(relationships, output_file, batch_count)\n",
    "        print(\"relationships created\")\n",
    "        return output_file\n",
    "\n",
    "    def save_to_file(self, relationships, output_file, batch_count):\n",
    "        mode = 'a' if batch_count > 0 else 'w'\n",
    "        with open(output_file, mode, newline='') as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=['source_label', 'target_label', 'relation', 'source', 'target', 'SAB'])\n",
    "            if batch_count == 0:\n",
    "                writer.writeheader()\n",
    "            for relationship in relationships:\n",
    "                writer.writerow(relationship)\n",
    "\n",
    "        print(\"Written to file: \", output_file, batch_count)\n",
    "\n",
    "    def run_queries(self, session, relationships):\n",
    "        for relationship in relationships:\n",
    "            source_label = relationship['source_label']\n",
    "            target_label = relationship['target_label']\n",
    "            relation = relationship['relation']\n",
    "            source = relationship['source']\n",
    "            target = relationship['target']\n",
    "            sab = relationship['SAB']\n",
    "            \n",
    "            query = f\"\"\"\n",
    "            MATCH (source:{source_label} {{CUI: '{source}'}}), (target:{target_label} {{CUI: '{target}'}})\n",
    "            CREATE (source)-[:{relation} {{SAB: '{relationship[\"SAB\"]}'}}]->(target)\n",
    "            \"\"\"\n",
    "            \n",
    "            session.run(query)\n",
    "\n",
    "    def generate_and_run_cql_queries_from_file(self, input_file='relationships_processed.csv'):\n",
    "        with self.driver.session() as session, open(input_file, mode='r') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            relationships = []\n",
    "            for relationship in reader:\n",
    "                relationships.append(relationship)\n",
    "                if len(relationships) >= self.batch_size:\n",
    "                    self.run_queries(session, relationships)\n",
    "                    relationships.clear()\n",
    "\n",
    "            if relationships:\n",
    "                self.run_queries(session, relationships)\n",
    "\n",
    "            print(\"Batch of queries run: \", len(relationships))\n",
    "\n",
    "    def cleanup(output_file='relationships_processed.csv'):\n",
    "        import os\n",
    "        \n",
    "        if os.path.exists(output_file):\n",
    "            os.remove(output_file)\n",
    "\n",
    "\n",
    "    def fetch_and_process_relationships(self, output_dir='relationships_processed'):\n",
    "        query = \"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM 'file:///relationships.tsv' AS row FIELDTERMINATOR ','\n",
    "        RETURN DISTINCT trim(row.sourceLabel) AS source_label, trim(row.targetLabel) AS target_label, trim(row.relation) AS relation, trim(row.source) AS source, trim(row.target) AS target, trim(row.SAB) as SAB\n",
    "        \"\"\"\n",
    "        import os\n",
    "        relationships = {}\n",
    "        if not os.path.exists(output_dir):\n",
    "                    os.makedirs(output_dir)\n",
    "\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(query)\n",
    "            for record in result:\n",
    "                key = (record['source_label'], record['target_label'], record['relation'])\n",
    "                if key not in relationships:\n",
    "                    relationships[key] = []\n",
    "                relationships[key].append({\n",
    "                    'source': record['source'],\n",
    "                    'target': record['target'], \n",
    "                    \"SAB\": record[\"SAB\"]\n",
    "                })\n",
    "\n",
    "                if len(relationships) >= 1000:\n",
    "                    for key, value_list in relationships.items():\n",
    "                        source_label, target_label, relation = key\n",
    "                        filename = f\"{output_dir}/{source_label}_{target_label}_{relation}.csv\"\n",
    "\n",
    "                        mode = 'a' if os.path.exists(filename) else 'w'\n",
    "                        with open(filename, mode, newline='') as file:\n",
    "                            writer = csv.writer(file)\n",
    "                            if mode == 'w':\n",
    "                                writer.writerow(['source_label', 'target_label', 'relation', 'source', 'target', 'SAB'])\n",
    "                            for value in value_list:\n",
    "                                writer.writerow([source_label, target_label, relation, value['source'], value['target'], value['SAB']])\n",
    "        \n",
    "                    print(\"relationships processed\", len(relationships))\n",
    "                    relationships.clear()\n",
    "        \n",
    "        # for key, value_list in relationships.items():\n",
    "        #     source_label, target_label, relation = key\n",
    "        #     filename = f\"{output_dir}/{source_label}_{target_label}_{relation}.csv\"\n",
    "        #     with open(filename, mode='w', newline='') as file:\n",
    "        #         writer = csv.writer(file)\n",
    "        #         writer.writerow(['source_label', 'target_label', 'relation', 'source', 'target', 'SAB'])\n",
    "        #         for value in value_list:\n",
    "        #             writer.writerow([source_label, target_label, relation, value['source'], value['target'], value['SAB']])\n",
    "        print(\"all relationships written\")\n",
    "        return output_dir\n",
    "\n",
    "    def generate_and_run_cql_queries_from_files(self, input_dir='processed_relationships'):\n",
    "        with self.driver.session() as session:\n",
    "            for filename in os.listdir(input_dir):\n",
    "                print(\"Processing\", filename)\n",
    "                if filename.endswith('.csv'):\n",
    "                    filepath = os.path.join(input_dir, filename)\n",
    "                    \n",
    "                    with open(filepath, mode='r') as file:\n",
    "                        reader = csv.DictReader(file)\n",
    "                        rows = [row for row in reader]\n",
    "                    \n",
    "                    if rows:\n",
    "                        source_label = rows[0]['source_label']\n",
    "                        target_label = rows[0]['target_label']\n",
    "                        relation = rows[0]['relation']\n",
    "                        \n",
    "                        query = f\"\"\"\n",
    "                        UNWIND $rows AS row\n",
    "                        MATCH (source:{source_label} {{CUI: row.source}}), (target:{target_label} {{CUI: row.target}})\n",
    "                        CREATE (source)-[:{relation} {{SAB: row.SAB}}]->(target)\n",
    "                        \"\"\"\n",
    "                        \n",
    "                        session.run(query, parameters={'rows': rows})\n",
    "                    \n",
    "                    # Delete the file after processing\n",
    "                    os.remove(filepath)\n",
    "\n",
    "            # Optionally, delete the directory if empty\n",
    "            if not os.listdir(input_dir):\n",
    "                os.rmdir(input_dir)\n",
    "\n",
    "uri = \"bolt://chiltepin.health.unm.edu:7687\"\n",
    "user = \"neo4j\"\n",
    "password = \"Hello@001\"\n",
    "\n",
    "importer = Neo4jImporter(uri, user, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd32005-aef5-44f3-aaea-212ae8fba9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n",
      "relationships processed 1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# importer.import_nodes()\n",
    "# importer.create_node_index()\n",
    "# importer.delete_duplicate_nodes()\n",
    "\n",
    "importer.fetch_and_process_relationships()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a623540-68a9-48ba-bf94-2eb347d6f9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "importer.generate_and_run_cql_queries_from_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd7dfd3-567d-4763-b314-bbb855b720db",
   "metadata": {},
   "outputs": [],
   "source": [
    "importer.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0d8079-5525-4a71-9df9-b89b51b7540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "importer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
